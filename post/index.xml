<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | MCJâ€˜s Homepage</title>
    <link>https://example.com/post/</link>
      <atom:link href="https://example.com/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hufaa3e52afb4cb9f91db856525a1f64a9_505081_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://example.com/post/</link>
    </image>
    
    <item>
      <title>A series of tuning methods have been released in modelscope.</title>
      <link>https://example.com/post/maastuning/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/maastuning/</guid>
      <description>&lt;p&gt;Lora, Prefix, Prompt, Adapter, SideTuning are the tuning methods for foundational model
tuning and well used in many downstream tasks. We have adopted these methods on basic multi-
modal pretrained model and released the code in &lt;a href=&#34;https://github.com/modelscope/modelscope&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelscope lib&lt;/a&gt;.
The model cards can be accessed in &lt;a href=&#34;https://www.modelscope.cn/models?page=1&amp;amp;tasks=foundation-model-application&amp;amp;type=cv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelscope&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Besides, we also propose and release the new methd U-Tuning in modelscope, you can
use it in &lt;a href=&#34;https://www.modelscope.cn/models/damo/cv_vitb16_classification_vision-efficient-tuning-utuning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelscope&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We release the MultimediaAI services for multimedia understanding.</title>
      <link>https://example.com/post/multimediaai/</link>
      <pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/post/multimediaai/</guid>
      <description>&lt;p&gt;MultimediaAI is an AI product to recognize the key structed information in multimedia (including
video, audio, image and text). The information covers video category, the famous person recognition, keywords recognition,
Optical Character Recognition(OCR), taging and detection of scene and object.&lt;/p&gt;
&lt;p&gt;To use these abilities, please refer to &lt;a href=&#34;http://retina.aliyun.com/#/Label&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
